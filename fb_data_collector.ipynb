{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import redis\n",
    "import json\n",
    "import uuid\n",
    "import copy\n",
    "\n",
    "access_token = 'EAACEdEose0cBAAW10d1q0lQJk6Y7VW49B0QZBd30SDPO6LsOhYRYdSSngG2GKVlqIcALOAih8JHgOBJfmExTCZCLLmAFIBQnxBnVnG5SBsEVbgIpzdX3vZCtoi2ILOdTOSETLLXRnZCHG5BvYDPhZBsXWttZCqI5QTO4S9PIgajneEMybHpnd4ZBzUZA6xnHgLMZD'\n",
    "\n",
    "start_time = ''\n",
    "\n",
    "end_time = ''\n",
    "\n",
    "red = redis.StrictRedis()\n",
    "unique_id = uuid.uuid4()\n",
    "\n",
    "dict_id_map = {'nissanusa' : '238312155374',\n",
    "              'lexus' : '90671958533',\n",
    "              'toyota' : '197052454200'\n",
    "#               'ford': '22166130048',\n",
    "#               'FordCars' : '55712353286',\n",
    "#               'chevrolet': '77589292295',\n",
    "#               'MazdaUSA': '337363685362',\n",
    "#               'cadillac': '95690769922',\n",
    "#               'Infiniti': '58128939954',\n",
    "#               'NissanElectric': '141137487795'\n",
    "              }\n",
    "\n",
    "id_brand_map = {'238312155374': 'nissanusa', \n",
    "               '90671958533': 'lexus', \n",
    "               '197052454200': 'toyota', \n",
    "#                '22166130048': 'ford', \n",
    "#                '55712353286': 'FordCars', \n",
    "#                '77589292295': 'chevrolet', \n",
    "#                '337363685362': 'MazdaUSA', \n",
    "#                '95690769922': 'cadillac', \n",
    "#                '58128939954': 'Infiniti', \n",
    "#                '141137487795': 'NissanElectric'\n",
    "               }\n",
    "\n",
    "\n",
    "reaction_list = ['like', 'love', 'angry', 'sad', 'haha', 'wow']\n",
    "\n",
    "start_time = '1483291277'\n",
    "\n",
    "end_time = 'now'\n",
    "\n",
    "class AutoVivification(dict):\n",
    "    \"\"\"Implementation of perl's autovivification feature.\"\"\"\n",
    "    def __getitem__(self, item):\n",
    "        try:\n",
    "            return dict.__getitem__(self, item)\n",
    "        except KeyError:\n",
    "            value = self[item] = type(self)()\n",
    "            return value\n",
    "        \n",
    "def nested_set(dic, keys, value):\n",
    "#     print(dic, keys)\n",
    "    for key in keys[:-1]:\n",
    "        dic = dic.setdefault(key, AutoVivification())\n",
    "    dic[keys[-1]] = value\n",
    "        \n",
    "data_id_map = AutoVivification()\n",
    "\n",
    "starting_urls = [\n",
    "                 ('https://graph.facebook.com/v3.0/'+dict_id_map[key]+'/posts?access_token='+access_token+'&pretty=0&'+start_time+'&until='+end_time, dict_id_map[key]) for key in dict_id_map\n",
    "                ]\n",
    "\n",
    "\n",
    "def f7(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "\n",
    "\n",
    "associated_id_map = []\n",
    "\n",
    "def generate_comments_data_url_by_postid(comment_id):\n",
    "#     r = requests.get('https://graph.facebook.com/v3.0/'+post_id+'/comments?access_token='+access_token)\n",
    "#     fb_comment_structure = json.loads(json.dumps(r.json()))\n",
    "#     pprint(fb_comment_structure)\n",
    "    return 'https://graph.facebook.com/v3.0/'+comment_id+'/comments?access_token='+access_token\n",
    "\n",
    "def populate_reaction_data(reaction_url, data, post_id, parent_id=None):\n",
    "    \n",
    "    if reaction_url is not None:\n",
    "        r_reactions = requests.get(reaction_url)\n",
    "        fb_reaction_structure = json.loads(json.dumps(r_reactions.json()))\n",
    "#         print(post_id, fb_reaction_structure)\n",
    "        ds = {}\n",
    "#         print(fb_reaction_structure)\n",
    "        ds['likes'] =   fb_reaction_structure[post_id]['like']['summary']['total_count'] if 'like' in fb_reaction_structure[post_id] else 0\n",
    "        ds['angries'] = fb_reaction_structure[post_id]['angry']['summary']['total_count'] if 'angry' in fb_reaction_structure[post_id] else 0\n",
    "        ds['sadnesses'] = fb_reaction_structure[post_id]['sad']['summary']['total_count'] if 'sad' in fb_reaction_structure[post_id] else 0\n",
    "        ds['hahas'] = fb_reaction_structure[post_id]['haha']['summary']['total_count'] if 'haha' in fb_reaction_structure[post_id] else 0\n",
    "        ds['wows'] = fb_reaction_structure[post_id]['wow']['summary']['total_count'] if 'wow' in fb_reaction_structure[post_id] else 0\n",
    "        ds['loves']= fb_reaction_structure[post_id]['love']['summary']['total_count'] if 'love' in fb_reaction_structure[post_id] else 0\n",
    "        if 'shares' in fb_reaction_structure[post_id]:\n",
    "            ds['shares'] = fb_reaction_structure[post_id]['shares']['count']\n",
    "        if 'comments' in fb_reaction_structure[post_id]:\n",
    "            ds['comments'] = fb_reaction_structure[post_id]['comments']['summary']['total_count']\n",
    "#         print('hello',ds)        \n",
    "        return ds\n",
    "\n",
    "def generate_comment_data(starting_url, idx, parent_id=None):\n",
    "    \n",
    "    comment_url = starting_url if starting_url != '' else None\n",
    "#     print(starting_url)\n",
    "    if comment_url is not None:\n",
    "        r = requests.get(comment_url)\n",
    "#     print(\"this is where it stops\")\n",
    "        fb_comment_structure = json.loads(json.dumps(r.json()))\n",
    "#         print(fb_comment_structure)\n",
    "#     if reaction_url is not None:\n",
    "#         r_reactions = requests.get(reaction_url)\n",
    "#         fb_reaction_structure = json.loads(json.dumps(r_reactions.json()))\n",
    "   \n",
    "    data = {}\n",
    "    if 'data' in fb_comment_structure:\n",
    "        for comment in fb_comment_structure['data']:\n",
    "            reaction_url = 'https://graph.facebook.com/v3.0/?access_token='+access_token+'&ids='+comment['id']+'&pretty=0&fields=reactions.type(LOVE).limit(0).summary(total_count).as(love),reactions.type(WOW).limit(0).summary(total_count).as(wow),reactions.type(HAHA).limit(0).summary(total_count).as(haha),reactions.type(ANGRY).limit(0).summary(total_count).as(angry),reactions.type(SAD).limit(0).summary(total_count).as(sad),reactions.type(LIKE).limit(0).summary(total_count).as(like)'\n",
    "            reaction_url_with_shares = 'https://graph.facebook.com/v3.0/?access_token='+access_token+'&ids='+comment['id']+'&pretty=0&fields=shares,reactions.type(LOVE).limit(0).summary(total_count).as(love),reactions.type(WOW).limit(0).summary(total_count).as(wow),reactions.type(HAHA).limit(0).summary(total_count).as(haha),reactions.type(ANGRY).limit(0).summary(total_count).as(angry),reactions.type(SAD).limit(0).summary(total_count).as(sad),reactions.type(LIKE).limit(0).summary(total_count).as(like),comments.limit(0).summary(true)'\n",
    "#             print(reaction_url_with_shares)\n",
    "            red.execute_command('JSON.SET', '1', '.', json.dumps(data_id_map))\n",
    "#             print(data_id_map)\n",
    "            if 'message' in comment:\n",
    "                data['id'] = comment['id']\n",
    "                data['comment'] = comment['message']\n",
    "                data['created_time'] = comment['created_time']\n",
    "                if parent_id is None:\n",
    "#                     print(comment['id'].split(\"_\")[0])\n",
    "                    if comment['id'].split(\"_\")[0] in id_brand_map:\n",
    "#                         print('full data')\n",
    "                        pop_data = populate_reaction_data(reaction_url_with_shares, data, comment['id'] ,data['id']) if comment['id'].split('_')[0] in id_brand_map else populate_reaction_data(reaction_url, data, comment['id'] ,data['id'])\n",
    "                        new_data = {**data, **pop_data}\n",
    "#                         print(new_data)    \n",
    "                        data_id_map[comment['id'].split(\"_\")[0]][new_data['id']] = new_data\n",
    "#                         for struct in\n",
    "                        \n",
    "                        generate_comment_data(generate_comments_data_url_by_postid(comment['id']), idx,  \n",
    "                                                  new_data['id'].split(\"_\")[0]+\":\"+new_data['id'])\n",
    "                    else:\n",
    "                        pop_data = populate_reaction_data(reaction_url_with_shares, data, comment['id'] ,data['id']) if comment['id'].split('_')[0] in id_brand_map else populate_reaction_data(reaction_url, data, comment['id'] ,data['id'])\n",
    "                        if idx in id_brand_map:\n",
    "                            if comment['id'].split(\"_\")[0] in id_brand_map[idx]:\n",
    "                                full_id = idx.split(\":\")\n",
    "                #                     print(\"before break\", full_id+[data['id']])\n",
    "                                new_data = {**data, **pop_data}\n",
    "\n",
    "                                nested_set(data_id_map, full_id+[new_data['id']], new_data)\n",
    "\n",
    "                                generate_comment_data(generate_comments_data_url_by_postid(new_data['id']), idx,\n",
    "                                                          idx+\":\"+new_data['id'])\n",
    "                            else:\n",
    "                                full_id = idx.split(\":\")\n",
    "                #                     print(\"before break\", full_id+[data['id']])\n",
    "                                new_data = {**data, **pop_data}\n",
    "\n",
    "                                nested_set(data_id_map, [idx]+full_id+[new_data['id']], new_data)\n",
    "\n",
    "                                generate_comment_data(generate_comments_data_url_by_postid(new_data['id']), idx,\n",
    "                                                          idx+\":\"+new_data['id'])\n",
    "                        else:\n",
    "                            new_data = {**data, **pop_data}\n",
    "                            data_id_map[idx][new_data['id']] = new_data\n",
    "                            generate_comment_data(generate_comments_data_url_by_postid(new_data['id']), idx, \n",
    "                                                      idx+\":\"+new_data['id'])\n",
    "                else:\n",
    "                    pop_data = populate_reaction_data(reaction_url_with_shares, data, comment['id']) if comment['id'].split('_')[0] in id_brand_map else populate_reaction_data(reaction_url, data, comment['id'])\n",
    "                    full_id = parent_id.split(\":\")\n",
    "#                     print(\"before break\", data)\n",
    "#                     print('asdf', populate_reaction_data(reaction_url, data, comment['id']))\n",
    "                    new_data = {**data, **pop_data}\n",
    "#                     print(new_data)\n",
    "                    nested_set(data_id_map, full_id+[data['id']], new_data)\n",
    "                    generate_comment_data(generate_comments_data_url_by_postid(new_data['id']), idx,\n",
    "                                              parent_id+\":\"+new_data['id'])\n",
    "                    \n",
    "#                 red.execute_command('JSON.SET', unique_id, '.', json.dumps(data))\n",
    "#                 reply = json.loads(red.execute_command('JSON.GET', unique_id))\n",
    "# #                     print(data)\n",
    "# #                 parent_id_request = requests.get('https://graph.facebook.com/v3.0/'+comment['id']+'comments?access_token='+access_token+'&filter=stream&fields=parent.fields(id)')\n",
    "# #                 parent_data = json.loads(json.dumps(parent_id_request.json()))\n",
    "#                 if 'data' in parent_data:\n",
    "#                     if len(parent_data['data']) > 0:\n",
    "#                         parent_idx = parent_data['data'][0]['id']\n",
    "                        \n",
    "#                 else:\n",
    "#                     generate_comment_data(generate_comments_data_url_by_postid(comment['id']), \n",
    "#                                           True, \n",
    "#                                           comment['id'].split(\"_\")[0])\n",
    "    \n",
    "            \n",
    "    if 'paging' in fb_comment_structure:\n",
    "        if 'next' in fb_comment_structure['paging']:\n",
    "#             print(fb_comment_structure['paging']['next'])\n",
    "            generate_comment_data(fb_comment_structure['paging']['next'], idx)\n",
    "for url in starting_urls:\n",
    "#     print(url)\n",
    "    generate_comment_data(url[0], url[1])\n",
    "\n",
    "    \n",
    "# df = pd.DataFrame(comments, columns=['id','comment','parent_id'])\n",
    "# df.to_csv('comment_data.csv', sep=',')\n",
    "# pprint(df)\n",
    "# print(len(comments))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
